{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T06:15:29.857928Z",
     "start_time": "2025-04-03T06:15:29.852560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from dnn import DeepNeuralNetwork\n",
    "from gradients import Adam\n",
    "from regularizations import L2Regularization, EarlyStopping"
   ],
   "id": "22a5f8c538d53cdb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-03T06:15:33.157470Z",
     "start_time": "2025-04-03T06:15:32.490525Z"
    }
   },
   "source": [
    "# Create XOR dataset\n",
    "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_xor = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# One-hot encoding\n",
    "y_xor_onehot = np.hstack([1 - y_xor, y_xor])\n",
    "\n",
    "# Initialize model\n",
    "dnn_xor = DeepNeuralNetwork(\n",
    "    layer_sizes=[2, 5, 5, 2],  # Input, hidden layers, output\n",
    "    activation_functions=[\"relu\", \"relu\", \"softmax\"],\n",
    "    optimizer=Adam(lr=0.01),\n",
    "    reg=L2Regularization(lambda_=0.001),\n",
    "    dropout_rate=0.2\n",
    ")\n",
    "\n",
    "# Train model\n",
    "early_stopping_xor = EarlyStopping(patience=5)\n",
    "dnn_xor.fit(X_xor, y_xor_onehot, epochs=100, batch_size=4, early_stopping=early_stopping_xor)\n",
    "\n",
    "# Predict\n",
    "predictions_xor = dnn_xor.predict(X_xor)\n",
    "print(\"XOR Predictions:\", np.argmax(predictions_xor, axis=1))"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,5) doesn't match the broadcast shape (2,5)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[0;32m     18\u001B[0m early_stopping_xor \u001B[38;5;241m=\u001B[39m EarlyStopping(patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m---> 19\u001B[0m dnn_xor\u001B[38;5;241m.\u001B[39mfit(X_xor, y_xor_onehot, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, early_stopping\u001B[38;5;241m=\u001B[39mearly_stopping_xor)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Predict\u001B[39;00m\n\u001B[0;32m     22\u001B[0m predictions_xor \u001B[38;5;241m=\u001B[39m dnn_xor\u001B[38;5;241m.\u001B[39mpredict(X_xor)\n",
      "File \u001B[1;32mD:\\DataspellProjects\\Deep Learning\\From Scratch\\dnn.py:86\u001B[0m, in \u001B[0;36mDeepNeuralNetwork.fit\u001B[1;34m(self, X, y, epochs, batch_size, early_stopping)\u001B[0m\n\u001B[0;32m     84\u001B[0m     X_batch, y_batch \u001B[38;5;241m=\u001B[39m X_shuffled[i:i \u001B[38;5;241m+\u001B[39m batch_size], y_shuffled[i:i \u001B[38;5;241m+\u001B[39m batch_size]\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(X_batch)\n\u001B[1;32m---> 86\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackward(y_batch)\n\u001B[0;32m     88\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss(y)\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m - Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\DataspellProjects\\Deep Learning\\From Scratch\\dnn.py:67\u001B[0m, in \u001B[0;36mDeepNeuralNetwork.backward\u001B[1;34m(self, y_true)\u001B[0m\n\u001B[0;32m     64\u001B[0m     dw \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregularization\u001B[38;5;241m.\u001B[39mgradient(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights[i]) \u001B[38;5;241m/\u001B[39m m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradients[i] \u001B[38;5;241m=\u001B[39m dw\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbiases[i] \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbiases[i], db)\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights[i] \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights[i], dw)\n",
      "\u001B[1;31mValueError\u001B[0m: non-broadcastable output operand with shape (1,5) doesn't match the broadcast shape (2,5)"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create linearly separable dataset\n",
    "np.random.seed(42)\n",
    "X_linsep = np.random.randn(200, 2)\n",
    "y_linsep = (X_linsep[:, 0] + 0.5 * X_linsep[:, 1] > 0).astype(int).reshape(-1, 1)\n",
    "\n",
    "# One-hot encoding\n",
    "y_linsep_onehot = np.hstack([1 - y_linsep, y_linsep])\n",
    "\n",
    "# Initialize model\n",
    "dnn_linsep = DeepNeuralNetwork(\n",
    "    layer_sizes=[2, 5, 5, 2],  # Input, hidden layers, output\n",
    "    activation_functions=[\"relu\", \"relu\", \"softmax\"],\n",
    "    optimizer=Adam(lr=0.01),\n",
    "    reg=L2Regularization(lambda_=0.001),\n",
    "    dropout_rate=0.2\n",
    ")\n",
    "\n",
    "# Train model\n",
    "early_stopping_linsep = EarlyStopping(patience=5)\n",
    "dnn_linsep.fit(X_linsep, y_linsep_onehot, epochs=50, batch_size=16, early_stopping=early_stopping_linsep)\n",
    "\n",
    "# Predict\n",
    "predictions_linsep = dnn_linsep.predict(X_linsep)\n",
    "print(\"Linear Data Predictions:\", np.argmax(predictions_linsep, axis=1))"
   ],
   "id": "c8cb1d6b880670"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create spiral dataset\n",
    "def generate_spiral_data(n_samples, n_classes):\n",
    "    np.random.seed(42)\n",
    "    X_spiral = np.zeros((n_samples * n_classes, 2))\n",
    "    y_spiral = np.zeros((n_samples * n_classes, 1), dtype=int)\n",
    "\n",
    "    for j in range(n_classes):\n",
    "        ix = range(n_samples * j, n_samples * (j + 1))\n",
    "        r = np.linspace(0.0, 1, n_samples)  # radius\n",
    "        t = np.linspace(j * 4, (j + 1) * 4, n_samples) + np.random.randn(n_samples) * 0.2  # theta\n",
    "        X_spiral[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n",
    "        y_spiral[ix] = j\n",
    "\n",
    "    return X_spiral, y_spiral\n",
    "\n",
    "X_spiral, y_spiral = generate_spiral_data(100, 2)\n",
    "\n",
    "# One-hot encoding\n",
    "y_spiral_onehot = np.hstack([1 - y_spiral, y_spiral])\n",
    "\n",
    "# Initialize model\n",
    "dnn_spiral = DeepNeuralNetwork(\n",
    "    layer_sizes=[2, 10, 10, 2],  # Input, hidden layers, output\n",
    "    activation_functions=[\"relu\", \"relu\", \"softmax\"],\n",
    "    optimizer=Adam(lr=0.01),\n",
    "    reg=L2Regularization(lambda_=0.001),\n",
    "    dropout_rate=0.2\n",
    ")\n",
    "\n",
    "# Train model\n",
    "early_stopping_spiral = EarlyStopping(patience=5)\n",
    "dnn_spiral.fit(X_spiral, y_spiral_onehot, epochs=100, batch_size=16, early_stopping=early_stopping_spiral)\n",
    "\n",
    "# Predict\n",
    "predictions_spiral = dnn_spiral.predict(X_spiral)\n",
    "print(\"Spiral Data Predictions:\", np.argmax(predictions_spiral, axis=1))\n"
   ],
   "id": "d4bee89b4658591c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
