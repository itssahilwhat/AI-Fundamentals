{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What is PyTorch?\n",
    "PyTorch is an open source machine learning and deep learning framework.\n",
    "\n",
    "## What can PyTorch be used for?\n",
    "PyTorch allows you to manipulate and process data and write machine learning algorithms using Python code.\n",
    "\n",
    "## Who uses PyTorch?\n",
    "Many of the world's largest technology companies such as Meta (Facebook), Tesla and Microsoft as well as artificial intelligence research companies such as OpenAI use PyTorch to power research and bring machine learning to their products.\n",
    "\n",
    "## Why use PyTorch?\n",
    "Machine learning researchers love using PyTorch. And as of February 2022, PyTorch is the most used deep learning framework on Papers With Code, a website for tracking machine learning research papers and the code repositories attached with them.\n",
    "\n",
    "PyTorch also helps take care of many things such as GPU acceleration (making your code run faster) behind the scenes.\n",
    "\n",
    "So you can focus on manipulating data and writing algorithms and PyTorch will make sure it runs fast.\n",
    "\n",
    "And if companies such as Tesla and Meta (Facebook) use it to build models they deploy to power hundreds of applications, drive thousands of cars and deliver content to billions of people, it's clearly capable on the development front too."
   ],
   "id": "2daf366873a29091"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-23T03:37:21.498028Z",
     "start_time": "2025-04-23T03:37:18.569672Z"
    }
   },
   "source": [
    "import torch\n",
    "torch.__version__"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0+cu124'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introduction to tensors(![Tensor docs](https://pytorch.org/docs/stable/tensors.html))\n",
    "Tensors are the fundamental building block of PyTorch.\n",
    "Tensors are a generalization of matrices to higher dimensions.\n",
    "Tensors are similar to NumPy arrays, but they have some key differences:\n",
    "- Tensors can be used on GPUs (graphics processing units) to accelerate computing.\n",
    "- Tensors can be used to build deep learning models.\n",
    "- Tensors can be used to build neural networks.\n",
    "\n",
    "Their job is to represent data in a numerical way.\n",
    "\n",
    "For example, you could represent an image as a tensor with shape [3, 224, 224] which would mean [colour_channels, height, width], as in the image has 3 colour channels (red, green, blue), a height of 224 pixels and a width of 224 pixels.\n",
    "\n",
    "## Creating tensors\n",
    "The first thing we're going to create is a scalar.\n",
    "A scalar is a single number and in tensor-speak it's a zero dimension tensor."
   ],
   "id": "baca8e2934093e64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:37:25.436039Z",
     "start_time": "2025-04-23T03:37:25.419806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ],
   "id": "d5bdfb45995b3fa9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:37:25.740441Z",
     "start_time": "2025-04-23T03:37:25.733357Z"
    }
   },
   "cell_type": "code",
   "source": "scalar.ndim",
   "id": "9bb6b7447bdea275",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:37:26.174915Z",
     "start_time": "2025-04-23T03:37:26.163327Z"
    }
   },
   "cell_type": "code",
   "source": "scalar.item()",
   "id": "af85a67c733ea9ec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Okay, now let's see a vector.\n",
    "\n",
    "A vector is a single dimension tensor but can contain many numbers.\n",
    "\n",
    "As in, you could have a vector [3, 2] to describe [bedrooms, bathrooms] in your house. Or you could have [3, 2, 2] to describe [bedrooms, bathrooms, car_parks] in your house.\n",
    "\n",
    "The important trend here is that a vector is flexible in what it can represent (the same with tensors)."
   ],
   "id": "350a42bbeb0661a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:37:27.120430Z",
     "start_time": "2025-04-23T03:37:27.109646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ],
   "id": "859cb7740f71875f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:37:27.635027Z",
     "start_time": "2025-04-23T03:37:27.625655Z"
    }
   },
   "cell_type": "code",
   "source": "vector.ndim",
   "id": "eb3b64618079cc8c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:37:28.159254Z",
     "start_time": "2025-04-23T03:37:28.150115Z"
    }
   },
   "cell_type": "code",
   "source": "vector.shape",
   "id": "8284e1d632fff9dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:37:28.741759Z",
     "start_time": "2025-04-23T03:37:28.729827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 10]])\n",
    "print(MATRIX)"
   ],
   "id": "b47ae819b082a309",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:37:39.422538Z",
     "start_time": "2025-04-23T03:37:39.415089Z"
    }
   },
   "cell_type": "code",
   "source": "MATRIX.ndim",
   "id": "9b4980637cd3eb6d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:37:45.006077Z",
     "start_time": "2025-04-23T03:37:44.992218Z"
    }
   },
   "cell_type": "code",
   "source": "MATRIX.shape",
   "id": "f33c175f9459b4cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:37:55.870514Z",
     "start_time": "2025-04-23T03:37:55.863619Z"
    }
   },
   "cell_type": "code",
   "source": "MATRIX.size()",
   "id": "dfcd2cb0c77164bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:38:42.292129Z",
     "start_time": "2025-04-23T03:38:42.280759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [4, 5 ,6],\n",
    "                       [7, 8, 9]]])\n",
    "TENSOR"
   ],
   "id": "d6c9ba8d9b7b7b5d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:38:48.805348Z",
     "start_time": "2025-04-23T03:38:48.799636Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR.ndim",
   "id": "589339803d181800",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:38:54.348637Z",
     "start_time": "2025-04-23T03:38:54.339907Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR.shape",
   "id": "356ba8ab4ee23f25",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:39:01.567627Z",
     "start_time": "2025-04-23T03:39:01.560120Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR.size()",
   "id": "33a51d8b0fcb5262",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<img src=\"Images/00-pytorch-different-tensor-dimensions.png\">",
   "id": "52b533c9898ecd9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Random tensors\n",
    "We've established tensors represent some form of data.\n",
    "\n",
    "And machine learning models such as neural networks manipulate and seek patterns within tensors.\n",
    "\n",
    "But when building machine learning models with PyTorch, it's rare you'll create tensors by hand (like what we've been doing).\n",
    "\n",
    "Instead, a machine learning model often starts out with large random tensors of numbers and adjusts these random numbers as it works through data to better represent it.\n",
    "\n",
    "In essence:\n",
    "\n",
    "Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...\n",
    "\n",
    "As a data scientist, you can define how the machine learning model starts (initialization), looks at data (representation) and updates (optimization) its random numbers."
   ],
   "id": "e3ab4faa44161a5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:43:20.787143Z",
     "start_time": "2025-04-23T03:43:20.707519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ],
   "id": "d137caac429967c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2524, 0.3894, 0.2999, 0.3894],\n",
       "         [0.8470, 0.0857, 0.1151, 0.4692],\n",
       "         [0.1140, 0.8895, 0.4464, 0.5055]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:44:23.316741Z",
     "start_time": "2025-04-23T03:44:23.306455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ],
   "id": "4941dad50b33be33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Zeros and ones\n",
    "Sometimes you'll just want to fill tensors with zeros or ones.\n",
    "\n",
    "This happens a lot with masking (like masking some of the values in one tensor with zeros to let a model know not to learn them)."
   ],
   "id": "d1526dc0e85725b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:45:29.147762Z",
     "start_time": "2025-04-23T03:45:29.132810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros, zeros.dtype"
   ],
   "id": "579e67bde757ae6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:45:45.390758Z",
     "start_time": "2025-04-23T03:45:45.379719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype"
   ],
   "id": "902c85524350e74c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:46:51.894774Z",
     "start_time": "2025-04-23T03:46:51.873038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zero_to_ten = torch.arange(start=0, end=10, step=2)\n",
    "zero_to_ten, zero_to_ten.dtype, zero_to_ten.ndim, zero_to_ten.shape"
   ],
   "id": "6dacc9bacdfbe6ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 2, 4, 6, 8]), torch.int64, 1, torch.Size([5]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:18:08.309933Z",
     "start_time": "2025-04-23T04:18:08.295725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ten_zeros = torch.zeros_like(input=zero_to_ten)\n",
    "ten_zeros, ten_zeros.dtype, ten_zeros.ndim, ten_zeros.shape"
   ],
   "id": "1361d02674767f7c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0]), torch.int64, 1, torch.Size([5]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:20:05.816754Z",
     "start_time": "2025-04-23T04:20:05.799741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded\n",
    "float_32_tensor, float_32_tensor.dtype, float_32_tensor.ndim, float_32_tensor.shape"
   ],
   "id": "2435503826f2a806",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.]), torch.float32, 1, torch.Size([3]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Aside from shape issues (tensor shapes don't match up), two of the other most common issues you'll come across in PyTorch are datatype and device issues.\n",
    "\n",
    "For example, one of tensors is torch.float32 and the other is torch.float16 (PyTorch often likes tensors to be the same format).\n",
    "\n",
    "Or one of your tensors is on the CPU and the other is on the GPU (PyTorch likes calculations between tensors to be on the same device)."
   ],
   "id": "bed8b87e7fdf7c37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:21:25.071964Z",
     "start_time": "2025-04-23T04:21:25.043992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16) # torch.half would also work\n",
    "float_16_tensor, float_16_tensor.dtype, float_16_tensor.ndim, float_16_tensor.shape"
   ],
   "id": "f6bb7916421e01ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.], dtype=torch.float16), torch.float16, 1, torch.Size([3]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:22:49.777640Z",
     "start_time": "2025-04-23T04:22:49.769115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ],
   "id": "2ec868eb643a49df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1026, 0.3963, 0.6784, 0.9381],\n",
      "        [0.5713, 0.9725, 0.7737, 0.4507],\n",
      "        [0.4507, 0.1358, 0.2803, 0.1061]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note: When you run into issues in PyTorch, it's very often one to do with one of the three attributes above. So when the error messages show up, sing yourself a little song called \"what, what, where\":\n",
    "\n",
    "\"what shape are my tensors? what datatype are they and where are they stored? what shape, what datatype, where where where\""
   ],
   "id": "57fe389ef20645bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tensor operations",
   "id": "2540498448f0de14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:24:23.134678Z",
     "start_time": "2025-04-23T04:24:23.109411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ],
   "id": "e155ad9231666fe8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:24:31.035100Z",
     "start_time": "2025-04-23T04:24:31.016828Z"
    }
   },
   "cell_type": "code",
   "source": "tensor * 10 # torch.multiply(tensor, 10)",
   "id": "7e753423069ff313",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:24:45.171428Z",
     "start_time": "2025-04-23T04:24:45.160150Z"
    }
   },
   "cell_type": "code",
   "source": "tensor - 10",
   "id": "bb8cf51fbacb072c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:24:50.471654Z",
     "start_time": "2025-04-23T04:24:50.455471Z"
    }
   },
   "cell_type": "code",
   "source": "tensor / 10",
   "id": "e1e965607ad92947",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:25:55.436878Z",
     "start_time": "2025-04-23T04:25:55.427093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# elementwise operations\n",
    "tensor * tensor"
   ],
   "id": "ebf3ef2aab9d1613",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:30:11.226675Z",
     "start_time": "2025-04-23T04:30:11.200898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch = torch.tensor([1, 2, 3])\n",
    "tensor.shape"
   ],
   "id": "7449649dd2b4698a",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m])\n\u001B[0;32m      2\u001B[0m tensor\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Tensor' object has no attribute 'tensor'"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:27:26.208687Z",
     "start_time": "2025-04-23T04:27:26.195721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The in-built torch.matmul() method is faster.\n",
    "tensor.matmul(tensor)"
   ],
   "id": "885229a0ffa5317f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:27:30.535512Z",
     "start_time": "2025-04-23T04:27:30.526258Z"
    }
   },
   "cell_type": "code",
   "source": "tensor @ tensor",
   "id": "f373cf5c38715b79",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## One of the most common errors in deep learning (shape errors)\n",
    "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches.\n",
    "\n",
    "We can make matrix multiplication work between tensor_A and tensor_B by making their inner dimensions match.\n",
    "\n",
    "One of the ways to do this is with a transpose (switch the dimensions of a given tensor).\n",
    "\n",
    "You can perform transposes in PyTorch using either:\n",
    "\n",
    "torch.transpose(input, dim0, dim1) - where input is the desired tensor to transpose and dim0 and dim1 are the dimensions to be swapped.\n",
    "tensor.T - where tensor is the desired tensor to transpose."
   ],
   "id": "5cc8614644facdd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:30:28.229022Z",
     "start_time": "2025-04-23T04:30:28.220704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11],\n",
    "                         [9, 12]], dtype=torch.float32)"
   ],
   "id": "573f8a3a50644bbd",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:30:47.744910Z",
     "start_time": "2025-04-23T04:30:47.733408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(tensor_A)\n",
    "print(tensor_B)"
   ],
   "id": "49cead5cce8ab890",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:33:16.317202Z",
     "start_time": "2025-04-23T04:33:16.275407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.T.shape}\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape}\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output)\n",
    "print(f\"\\nOutput Shape: {output.shape}\")"
   ],
   "id": "ae1a4df9ae5f77c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "New shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([2, 3])\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3])\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output Shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:33:58.565610Z",
     "start_time": "2025-04-23T04:33:58.556770Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.mm(tensor_A, tensor_B.T))",
   "id": "c9fedafccd1772c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Linear\n",
    "Applies a linear transformation to the incoming data:\n",
    "$$\n",
    "y = xA^T + b\n",
    "$$"
   ],
   "id": "f173a0319cc229c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T04:37:41.522120Z",
     "start_time": "2025-04-23T04:37:41.498567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "linear = torch.nn.Linear(in_features=2, out_features=6, bias=True, device=None, dtype=None)\n",
    "\n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output: {output}\\n\")\n",
    "print(f\"Output shape: {output.shape}\\n\")"
   ],
   "id": "b09bbcc29d4bbb2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output: tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## aggregation",
   "id": "e8b73cdbb93f9a0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:03:47.022790Z",
     "start_time": "2025-04-23T05:03:47.009880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ],
   "id": "b2f9a1b972133089",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:04:39.905326Z",
     "start_time": "2025-04-23T05:04:39.889605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Maximum: {x.max()}\")\n",
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
    "print(f\"Sum: {x.sum()}\")"
   ],
   "id": "460b5a9e3cab0439",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum: 90\n",
      "Minimum: 0\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:05:17.493843Z",
     "start_time": "2025-04-23T05:05:17.481859Z"
    }
   },
   "cell_type": "code",
   "source": "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)",
   "id": "402e541ffb9072b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(0), tensor(45.), tensor(450))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:05:43.345330Z",
     "start_time": "2025-04-23T05:05:43.320704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a tensor\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "# Returns index of max and min values\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")"
   ],
   "id": "8664cd914706cd6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:06:36.898135Z",
     "start_time": "2025-04-23T05:06:36.888373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = torch.arange(10., 100., 10.)\n",
    "tensor.dtype"
   ],
   "id": "f3c6d76fed4eb8ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:07:23.346838Z",
     "start_time": "2025-04-23T05:07:23.334503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16"
   ],
   "id": "27f1a5d0b2f3b11a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:07:23.945036Z",
     "start_time": "2025-04-23T05:07:23.936234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8"
   ],
   "id": "63a5653f3a4669cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing\n",
    "torch.reshape(input, shape)\tReshapes input to shape (if compatible), can also use torch.Tensor.reshape().\n",
    "\n",
    "Tensor.view(shape)\tReturns a view of the original tensor in a different shape but shares the same data as the original tensor.\n",
    "\n",
    "torch.stack(tensors, dim=0)\tConcatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.\n",
    "\n",
    "torch.squeeze(input)\tSqueezes input to remove all the dimenions with value 1.\n",
    "\n",
    "torch.unsqueeze(input, dim)\tReturns input with a dimension value of 1 added at dim.\n",
    "\n",
    "torch.permute(input, dims)\tReturns a view of the original input with its dimensions permuted (rearranged) to dims.\n",
    "\n",
    "Why do any of these?\n",
    "\n",
    "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors."
   ],
   "id": "8aa4bbaa419476cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:17:17.523466Z",
     "start_time": "2025-04-23T06:17:17.503280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ],
   "id": "fcfdd0432e3b90e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:17:30.999595Z",
     "start_time": "2025-04-23T06:17:30.989291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_reshaped = x.reshape(1, 7)\n",
    "x_reshaped, x_reshaped.shape"
   ],
   "id": "c0ca0a3d61f92824",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:17:51.382031Z",
     "start_time": "2025-04-23T06:17:51.373894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Change view (keeps same data as original but changes view)\n",
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ],
   "id": "9744df04744849d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Both `torch.view` and `torch.reshape` are used to reshape tensors in PyTorch, but they have key differences. `torch.view` always returns a view of the original tensor, meaning the reshaped tensor shares the same underlying data, and changes in one reflect in the other. However, it requires the tensor to be contiguous in memory, and will raise an error otherwiseâ€”such as when attempting to reshape a transposed tensor without calling `.contiguous()` first. In contrast, `torch.reshape`, introduced in version 0.4, can reshape both contiguous and non-contiguous tensors and attempts to return a view when possible, but may return a copy instead. This behavior is not guaranteed and depends on memory layout. Therefore, you cannot rely on `reshape()` to share data with the original tensor. As per PyTorch developers, if you need a copy, use `clone()`, and if you want to ensure shared storage, use `view()`. In summary, use `reshape()` for general reshaping and `view()` when you explicitly require shared data and the tensor is contiguous.",
   "id": "bf294fbac7991d89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:23:55.002419Z",
     "start_time": "2025-04-23T06:23:54.984232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Changing z changes x\n",
    "z[:, 0] = 5\n",
    "z, x"
   ],
   "id": "15ec8d3749c63746",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:24:37.482699Z",
     "start_time": "2025-04-23T06:24:37.466894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_stacked = torch.stack([x, x ,x ,x], dim=0) # try changing dim to dim=1 and see what happens\n",
    "x_stacked, x_stacked.shape"
   ],
   "id": "6b60374949154f88",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "         [5., 2., 3., 4., 5., 6., 7.],\n",
       "         [5., 2., 3., 4., 5., 6., 7.],\n",
       "         [5., 2., 3., 4., 5., 6., 7.]]),\n",
       " torch.Size([4, 7]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:45:17.731609Z",
     "start_time": "2025-04-23T06:45:17.709043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"New tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ],
   "id": "45b7007726e58745",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "Previous shape: torch.Size([1, 7])\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "New shape: torch.Size([7])\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:45:40.463140Z",
     "start_time": "2025-04-23T06:45:40.448943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ],
   "id": "53dd1000adeb85dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "Previous shape: torch.Size([7])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "New shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:46:41.469984Z",
     "start_time": "2025-04-23T06:46:41.461864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Original shape: {x_original.shape}\")\n",
    "print(f\"Permuted shape: {x_permuted.shape}\")"
   ],
   "id": "8117afdbad407757",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([224, 224, 3])\n",
      "Permuted shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Because permuting returns a view (shares the same data as the original), the values in the permuted tensor will be the same as the original tensor and if you change the values in the view, it will change the values of the original.",
   "id": "8224aa02c715bd74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Indexing (selecting data from tensors)",
   "id": "3ba36b7e8d24c7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:47:42.424640Z",
     "start_time": "2025-04-23T06:47:42.404845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ],
   "id": "eaeb8969c0254823",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:47:48.074275Z",
     "start_time": "2025-04-23T06:47:48.057093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's index bracket by bracket\n",
    "print(f\"First square bracket:\\n{x[0]}\")\n",
    "print(f\"Second square bracket: {x[0][0]}\")\n",
    "print(f\"Third square bracket: {x[0][0][0]}\")"
   ],
   "id": "acdd1b917f15a0f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First square bracket:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket: tensor([1, 2, 3])\n",
      "Third square bracket: 1\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:48:23.529246Z",
     "start_time": "2025-04-23T06:48:23.517379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
    "print(x[:, 0])"
   ],
   "id": "82870cd7f9435469",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3]])\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:48:33.713832Z",
     "start_time": "2025-04-23T06:48:33.706186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
    "print(x[:, :, 1])"
   ],
   "id": "7edc7dc4cc35e188",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 5, 8]])\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:49:30.269082Z",
     "start_time": "2025-04-23T06:49:30.258917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ],
   "id": "104bab2ce545d9fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:49:37.658912Z",
     "start_time": "2025-04-23T06:49:37.643225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
    "x[0, 0, :] # same as x[0][0]"
   ],
   "id": "585d1a548e5f33d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PyTorch tensors & NumPy",
   "id": "8995cceb77f5d84c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:54:20.456587Z",
     "start_time": "2025-04-23T06:54:20.444736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ],
   "id": "65cec1fe427d1e01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "By default, NumPy arrays are created with the datatype float64 and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
    "\n",
    "However, many PyTorch calculations default to using float32.\n",
    "\n",
    "So if you want to convert your NumPy array (float64) -> PyTorch tensor (float64) -> PyTorch tensor (float32), you can use tensor = torch.from_numpy(array).type(torch.float32)"
   ],
   "id": "ccef3ab260e13549"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:54:28.260574Z",
     "start_time": "2025-04-23T06:54:28.240176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "array = array + 1  # tensor unchanged, but if we use array += 1 tensor will also change.\n",
    "array, tensor"
   ],
   "id": "d8b546ee3f13da48",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:57:11.340060Z",
     "start_time": "2025-04-23T06:57:11.314325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ],
   "id": "16098f67f6e31218",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T06:57:31.466410Z",
     "start_time": "2025-04-23T06:57:31.457359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Change the tensor, keep the array the same\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ],
   "id": "806d73801615c9bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Reproducibility (trying to take the random out of random)\n",
    "\n",
    "As you learn more about neural networks and machine learning, you'll start to discover how much randomness plays a part.\n",
    "\n",
    "Well, pseudorandomness that is. Because after all, as they're designed, a computer is fundamentally deterministic (each step is predictable) so the randomness they create are simulated randomness (though there is debate on this too, but since I'm not a computer scientist, I'll let you find out more yourself).\n",
    "\n",
    "How does this relate to neural networks and deep learning then?\n",
    "\n",
    "We've discussed neural networks start with random numbers to describe patterns in data (these numbers are poor descriptions) and try to improve those random numbers using tensor operations (and a few other things we haven't discussed yet) to better describe patterns in data.\n",
    "\n",
    "In short:\n",
    "\n",
    "start with random numbers -> tensor operations -> try to make better (again and again and again)\n",
    "\n",
    "Although randomness is nice and powerful, sometimes you'd like there to be a little less randomness.\n",
    "\n",
    "Why?\n",
    "\n",
    "So you can perform repeatable experiments.\n",
    "\n",
    "For example, you create an algorithm capable of achieving X performance.\n",
    "\n",
    "And then your friend tries it out to verify you're not crazy.\n",
    "\n",
    "How could they do such a thing?\n",
    "\n",
    "That's where reproducibility comes in.\n",
    "\n",
    "In other words, can you get the same (or very similar) results on your computer running the same code as I get on mine?"
   ],
   "id": "96d8ea7cfce08ec3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:36:54.607900Z",
     "start_time": "2025-04-23T08:36:54.564254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Are they equal? {random_tensor_A == random_tensor_B}\")"
   ],
   "id": "5138589c24407c89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.8016, 0.3649, 0.6286, 0.9663],\n",
      "        [0.7687, 0.4566, 0.5745, 0.9200],\n",
      "        [0.3230, 0.8613, 0.0919, 0.3102]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.9536, 0.6002, 0.0351, 0.6826],\n",
      "        [0.3743, 0.5220, 0.1336, 0.9666],\n",
      "        [0.9754, 0.8474, 0.8988, 0.1105]])\n",
      "\n",
      "Are they equal? tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:40:06.904239Z",
     "start_time": "2025-04-23T08:40:06.884842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "RANDOM_SEED = 42 # try changing this to different values and see what happens to the numbers below\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called\n",
    "# Without this, tensor_D would be different to tensor_C\n",
    "torch.manual_seed(RANDOM_SEED) # try commenting this line out and seeing what happens\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"Are they equal? {random_tensor_C == random_tensor_D}\")"
   ],
   "id": "da5dc0669e77470e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Are they equal? tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Key Point: Exact reproducibility across different PyTorch versions, commits, platforms (CPU vs GPU) is not guaranteed, even with the same seed.\n",
    "\n",
    "However, you can reduce nondeterminism on a specific platform, device, and PyTorch version by doing two things:\n",
    "\n",
    "Control sources of randomness (seeds).\n",
    "\n",
    "Configure PyTorch to use deterministic algorithms, which ensures operations return the same result for the same input.\n",
    "\n",
    "âš ï¸ Note: Deterministic operations can be slower but are helpful during development (e.g., debugging, testing).\n",
    "\n"
   ],
   "id": "e181a4ccaf900c7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:00:36.990837Z",
     "start_time": "2025-04-23T09:00:36.625511Z"
    }
   },
   "cell_type": "code",
   "source": "!nvidia-smi",
   "id": "5841f4d9f36fd706",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 23 14:30:36 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 572.70                 Driver Version: 572.70         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   51C    P8              3W /   60W |     290MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            4688    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A            9292    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A           11000    C+G   ...4__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A           17104    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A           18608    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           21228    C+G   ....0.3179.85\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           22632    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           22768    C+G   ...DataSpell\\bin\\dataspell64.exe      N/A      |\n",
      "|    0   N/A  N/A           22792    C+G   ...4__t4vj0pshhgkwm\\Telegram.exe      N/A      |\n",
      "|    0   N/A  N/A           28236    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           29516    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:01:12.300804Z",
     "start_time": "2025-04-23T09:01:12.193328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for GPU\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "id": "75dbc6fdbf44fbec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:01:28.117450Z",
     "start_time": "2025-04-23T09:01:28.104194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "id": "588dd6d0a8dd00ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:02:34.485473Z",
     "start_time": "2025-04-23T09:02:34.469159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ],
   "id": "90cc75e4b32bca68",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:48:21.223386Z",
     "start_time": "2025-04-23T09:48:20.761752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create tensor (default on CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ],
   "id": "96f7a662260e9c74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:48:50.219663Z",
     "start_time": "2025-04-23T09:48:49.891226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
    "tensor_on_gpu.numpy()"
   ],
   "id": "43b95f6c2cb26b76",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[94], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# If tensor is on GPU, can't transform it to NumPy (this will error)\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m tensor_on_gpu\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:49:03.145597Z",
     "start_time": "2025-04-23T09:49:03.114037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instead, copy the tensor back to cpu\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ],
   "id": "5d15f6f1a925a23e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:49:08.397517Z",
     "start_time": "2025-04-23T09:49:08.386662Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_on_gpu",
   "id": "b358675679ca70af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exercise",
   "id": "9a8c32d6a197d4cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:50:34.313595Z",
     "start_time": "2025-04-23T09:50:34.295214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_A = torch.randn(7, 7)\n",
    "tensor_A"
   ],
   "id": "14e090bcbce01626",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1441,  0.3383,  1.6992,  0.0109, -0.3387, -1.3407, -0.5854],\n",
       "        [ 0.5362,  1.0563, -1.4692,  1.4332,  0.7440, -0.4816, -1.0495],\n",
       "        [ 0.6039, -1.7223, -1.3543, -0.4976,  0.4747, -2.5095,  0.4880],\n",
       "        [ 0.7846,  0.0286,  0.6408, -1.3527,  0.2191,  0.5526, -0.1853],\n",
       "        [ 0.7528,  0.4048,  0.1785,  0.2649,  0.5886, -0.5797, -0.1691],\n",
       "        [ 1.9312,  1.0119, -1.4364, -1.1299, -0.1360,  1.6354,  0.6793],\n",
       "        [ 0.4405,  1.1415,  0.0186, -1.8058,  0.9254, -0.3753,  1.0331]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:50:45.398597Z",
     "start_time": "2025-04-23T09:50:45.391230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_B = torch.randn(1, 7)\n",
    "tensor_B"
   ],
   "id": "e76d182a962d6924",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8448, -0.1627,  1.3187,  0.5707,  1.2832,  0.0538, -0.3380]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:51:32.156912Z",
     "start_time": "2025-04-23T09:51:32.144074Z"
    }
   },
   "cell_type": "code",
   "source": "print(tensor_A.matmul(tensor_B.T))",
   "id": "c8765f03f0c68249",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.1637e-01],\n",
      "        [ 4.4508e-01],\n",
      "        [-9.7049e-01],\n",
      "        [ 1.1046e+00],\n",
      "        [ 1.7379e+00],\n",
      "        [-1.3885e+00],\n",
      "        [-1.5606e-03]])\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:52:22.521236Z",
     "start_time": "2025-04-23T09:52:22.507900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_SEED = 0\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "tensor_C = torch.randn(7, 7)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "tensor_D = torch.randn(1, 7)\n",
    "\n",
    "print(tensor_C.matmul(tensor_D.T))"
   ],
   "id": "afd7d01d38faacba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.1132],\n",
      "        [-0.4052],\n",
      "        [ 2.2938],\n",
      "        [-4.9556],\n",
      "        [-0.9954],\n",
      "        [ 1.9452],\n",
      "        [ 2.2410]])\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T11:59:31.124570Z",
     "start_time": "2025-04-23T11:59:29.963737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_SEED = 0\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "tensor_E = torch.randn(7, 7).to(device)\n",
    "\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "tensor_F = torch.randn(1, 7).to(device)\n",
    "\n",
    "print(tensor_E.matmul(tensor_F.T))"
   ],
   "id": "58a17256b020ed95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5522],\n",
      "        [ 1.1752],\n",
      "        [ 0.5535],\n",
      "        [ 0.4791],\n",
      "        [-0.0275],\n",
      "        [ 1.3365],\n",
      "        [-0.8435]], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T12:01:23.886061Z",
     "start_time": "2025-04-23T12:01:23.866141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_SEED = 1234\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "tensor_G = torch.randn(2, 3).to(device)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "tensor_H = torch.randn(2, 3).to(device)\n",
    "\n",
    "output = tensor_G.matmul(tensor_H.T)\n",
    "print(output)"
   ],
   "id": "5a44360ccc9e8a12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1872, -0.7458],\n",
      "        [-0.7458,  0.6755]], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T12:01:45.495969Z",
     "start_time": "2025-04-23T12:01:45.486732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Min: {output.min()}\")\n",
    "print(f\"Max: {output.max()}\")"
   ],
   "id": "c2731e0dc3857af3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: -0.7457990646362305\n",
      "Max: 1.1872471570968628\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T12:05:41.765076Z",
     "start_time": "2025-04-23T12:05:41.746840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_I = torch.randn(1, 1, 1, 10)\n",
    "\n",
    "torch.manual_seed(7)\n",
    "tensor_J = tensor_I.squeeze()\n",
    "\n",
    "print(f\"Tensor I: {tensor_I}\")\n",
    "print(f\" Tensor I shape: {tensor_I.shape}\")\n",
    "print(f\"Tensor J: {tensor_J}\")\n",
    "print(f\" Tensor J shape: {tensor_J.shape}\")"
   ],
   "id": "c2d798a8e40a6e79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor I: tensor([[[[ 0.2310,  0.6931, -0.2669,  2.1785,  0.1021, -0.2590, -0.1549,\n",
      "           -1.3706, -0.1319,  0.8848]]]])\n",
      " Tensor I shape: torch.Size([1, 1, 1, 10])\n",
      "Tensor J: tensor([ 0.2310,  0.6931, -0.2669,  2.1785,  0.1021, -0.2590, -0.1549, -1.3706,\n",
      "        -0.1319,  0.8848])\n",
      " Tensor J shape: torch.Size([10])\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d936222f1d5e0cc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
