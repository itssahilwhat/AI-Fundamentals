{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## kNN Classifier",
   "id": "48d386f74357d46f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T06:30:49.790647Z",
     "start_time": "2025-04-29T06:30:49.783207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import warnings"
   ],
   "id": "432f0e82e92aa270",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T06:30:53.980612Z",
     "start_time": "2025-04-29T06:30:50.578873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load CIFAR-10 dataset using PyTorch\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "# Prepare data for kNN (flatten images)\n",
    "X_train = trainset.data.reshape(trainset.data.shape[0], -1).astype(np.float32)\n",
    "y_train = np.array(trainset.targets)\n",
    "X_test = testset.data.reshape(testset.data.shape[0], -1).astype(np.float32)\n",
    "y_test = np.array(testset.targets)\n",
    "\n",
    "# Normalize the data\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ],
   "id": "8558f52540a941cd",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T06:44:02.273994Z",
     "start_time": "2025-04-29T06:31:01.682870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to evaluate kNN with different hyperparameters\n",
    "def evaluate_knn(k_values, distance_metrics, X_train, y_train, X_val, y_val):\n",
    "    results = {}\n",
    "    for k in k_values:\n",
    "        for metric in distance_metrics:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, algorithm='auto')\n",
    "            knn.fit(X_train, y_train)\n",
    "            val_acc = knn.score(X_val, y_val)\n",
    "            results[(k, metric)] = val_acc\n",
    "            print(f\"k={k}, metric={metric}: Validation Accuracy = {val_acc:.4f}\")\n",
    "    return results\n",
    "\n",
    "# Hyperparameter tuning for kNN\n",
    "k_values = [1, 3, 5, 10, 20]\n",
    "distance_metrics = ['l2']\n",
    "knn_results = evaluate_knn(k_values, distance_metrics, X_train_split, y_train_split, X_val, y_val)"
   ],
   "id": "88b03a16c0b84023",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, metric=l2: Validation Accuracy = 0.3357\n",
      "k=3, metric=l2: Validation Accuracy = 0.3215\n",
      "k=5, metric=l2: Validation Accuracy = 0.3325\n",
      "k=10, metric=l2: Validation Accuracy = 0.3292\n",
      "k=20, metric=l2: Validation Accuracy = 0.3180\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T07:38:43.321540Z",
     "start_time": "2025-04-29T07:37:37.584919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cross-validation for kNN with optimizations\n",
    "def cross_validate_knn(k_values, distance_metrics, X, y, cv=3):\n",
    "    results = {}\n",
    "    # Use a subset of data for faster cross-validation\n",
    "    subset_size = 5000  # Reduce this if still too slow\n",
    "    X_subset, _, y_subset, _ = train_test_split(X, y, train_size=subset_size, random_state=42)\n",
    "\n",
    "    for k in k_values:\n",
    "        for metric in distance_metrics:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric, algorithm='auto')\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                # Use fewer folds and subset of data\n",
    "                scores = cross_val_score(knn, X_subset, y_subset, cv=cv, n_jobs=-1)\n",
    "            results[(k, metric)] = np.mean(scores)\n",
    "            print(f\"k={k}, metric={metric}: Cross-Validation Accuracy = {np.mean(scores):.4f} (std={np.std(scores):.4f})\")\n",
    "    return results\n",
    "\n",
    "cv_results = cross_validate_knn(k_values, distance_metrics, X_train, y_train, cv=3)"
   ],
   "id": "780c969d5d339310",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, metric=l2: Cross-Validation Accuracy = 0.2590 (std=0.0091)\n",
      "k=3, metric=l2: Cross-Validation Accuracy = 0.2568 (std=0.0048)\n",
      "k=5, metric=l2: Cross-Validation Accuracy = 0.2546 (std=0.0047)\n",
      "k=10, metric=l2: Cross-Validation Accuracy = 0.2620 (std=0.0046)\n",
      "k=20, metric=l2: Cross-Validation Accuracy = 0.2650 (std=0.0037)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T07:38:43.392176Z",
     "start_time": "2025-04-29T07:38:43.385328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the best hyperparameters\n",
    "best_params = max(cv_results, key=cv_results.get)\n",
    "best_accuracy = cv_results[best_params]\n",
    "print(f\"\\nBest hyperparameters: k={best_params[0]}, metric={best_params[1]}\")\n",
    "print(f\"Best cross-validation accuracy: {best_accuracy:.4f}\")"
   ],
   "id": "934fec1a03c8ca44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters: k=20, metric=l2\n",
      "Best cross-validation accuracy: 0.2650\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear Classifier, SVM Loss, and Softmax Loss",
   "id": "e179a520cf1fe935"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T06:28:14.060241Z",
     "start_time": "2025-04-29T06:28:10.018416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ],
   "id": "42b8c58f5af42df9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "X_train = trainset.data.reshape(trainset.data.shape[0], -1).astype(np.float32)\n",
    "y_train = np.array(trainset.targets)\n",
    "X_test = testset.data.reshape(testset.data.shape[0], -1).astype(np.float32)\n",
    "y_test = np.array(testset.targets)\n",
    "\n",
    "# Normalize the data\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "# Add bias term\n",
    "X_train = np.hstack((X_train, np.ones((X_train.shape[0], 1))))\n",
    "X_test = np.hstack((X_test, np.ones((X_test.shape[0], 1))))\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ],
   "id": "7a6e67b6b1ccfd67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Multiclass SVM Loss\n",
    "def svm_loss(scores, labels, delta=1.0):\n",
    "    batch_size = scores.size(0)\n",
    "    correct_class_scores = scores[torch.arange(batch_size), labels].view(-1, 1)\n",
    "    margins = torch.max(torch.zeros_like(scores), scores - correct_class_scores + delta)\n",
    "    margins[torch.arange(batch_size), labels] = 0\n",
    "    loss = torch.mean(torch.sum(margins, dim=1))\n",
    "    return loss\n",
    "\n",
    "def softmax_loss(scores, labels):\n",
    "    batch_size = scores.size(0)\n",
    "    scores = scores - torch.max(scores, dim=1, keepdim=True).values\n",
    "    exp_scores = torch.exp(scores)\n",
    "    prob = exp_scores / torch.sum(exp_scores, dim=1, keepdim=True)\n",
    "    loss = -torch.mean(torch.log(prob[torch.arange(batch_size), labels]))\n",
    "    return loss"
   ],
   "id": "faab672286f6f18b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_size = X_train.shape[1]\n",
    "num_classes = 10\n",
    "model = LinearClassifier(input_size, num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)"
   ],
   "id": "484976a352012ea0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T06:28:16.084142Z",
     "start_time": "2025-04-29T06:28:14.840716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop for SVM Loss\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    scores = model(X_train_tensor)\n",
    "    loss = svm_loss(scores, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, SVM Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate on test set using SVM Loss\n",
    "model.eval()\n",
    "test_scores = model(X_test_tensor)\n",
    "svm_test_loss = svm_loss(test_scores, y_test_tensor)\n",
    "print(f\"SVM Test Loss: {svm_test_loss.item():.4f}\")"
   ],
   "id": "796860dc9b355f6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, SVM Loss: 9.0546\n",
      "Epoch 2, SVM Loss: 9.0468\n",
      "Epoch 3, SVM Loss: 7.8521\n",
      "Epoch 4, SVM Loss: 7.6262\n",
      "Epoch 5, SVM Loss: 7.4045\n",
      "Epoch 6, SVM Loss: 7.0860\n",
      "Epoch 7, SVM Loss: 6.6570\n",
      "Epoch 8, SVM Loss: 6.4565\n",
      "Epoch 9, SVM Loss: 6.5708\n",
      "Epoch 10, SVM Loss: 6.3879\n",
      "SVM Test Loss: 6.0771\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T06:28:18.143025Z",
     "start_time": "2025-04-29T06:28:17.795156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop for Softmax Loss\n",
    "model = LinearClassifier(input_size, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    scores = model(X_train_tensor)\n",
    "    loss = softmax_loss(scores, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Softmax Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate on test set using Softmax Loss\n",
    "model.eval()\n",
    "test_scores = model(X_test_tensor)\n",
    "softmax_test_loss = softmax_loss(test_scores, y_test_tensor)\n",
    "print(f\"Softmax Test Loss: {softmax_test_loss.item():.4f}\")"
   ],
   "id": "2f1e030c0dfed026",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Softmax Loss: 2.3394\n",
      "Epoch 2, Softmax Loss: 2.7214\n",
      "Epoch 3, Softmax Loss: 2.4415\n",
      "Epoch 4, Softmax Loss: 2.2715\n",
      "Epoch 5, Softmax Loss: 2.3993\n",
      "Epoch 6, Softmax Loss: 2.3230\n",
      "Epoch 7, Softmax Loss: 2.2278\n",
      "Epoch 8, Softmax Loss: 2.2289\n",
      "Epoch 9, Softmax Loss: 2.2345\n",
      "Epoch 10, Softmax Loss: 2.1771\n",
      "Softmax Test Loss: 2.1165\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
